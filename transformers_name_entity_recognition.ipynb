{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqCUFFWEXVFBNa+Cd3/8Z5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd47c8ccf37843a094aff0fffb2a0d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d9f0d5ddb594c1f972563d09d237590",
              "IPY_MODEL_af8996acd53649a4be594e38b10e30af",
              "IPY_MODEL_a1f6e548667946c4b466116615dbbd9e"
            ],
            "layout": "IPY_MODEL_9a118dce66cc4d6cb3725dd5f90fe21a"
          }
        },
        "0d9f0d5ddb594c1f972563d09d237590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4bc402544ea4d76a4a974e7ecc2c170",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1920f6d2944c54a898fa1689fdfa14",
            "value": "model.safetensors: 100%"
          }
        },
        "af8996acd53649a4be594e38b10e30af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef37c6ca73f0442b8303d5bd6a438508",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd6795d7db4641f8b72dadc029d85cf7",
            "value": 498818054
          }
        },
        "a1f6e548667946c4b466116615dbbd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b65a692dafa946f8b95144baa4be369a",
            "placeholder": "​",
            "style": "IPY_MODEL_f13b0c532a264b01a581a571badf9a74",
            "value": " 499M/499M [00:08&lt;00:00, 58.5MB/s]"
          }
        },
        "9a118dce66cc4d6cb3725dd5f90fe21a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bc402544ea4d76a4a974e7ecc2c170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1920f6d2944c54a898fa1689fdfa14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef37c6ca73f0442b8303d5bd6a438508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6795d7db4641f8b72dadc029d85cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b65a692dafa946f8b95144baa4be369a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13b0c532a264b01a581a571badf9a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudheer-muthyala/Transformers_HuggingFace_Tensorflow/blob/main/transformers_name_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "COUn3NzjfcQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BRzuNGF5iiR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from transformers import RobertaTokenizerFast, DataCollatorForTokenClassification, TFRobertaForTokenClassification, create_optimizer\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "dqEd0ArC5o7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoARJI8X5pB7",
        "outputId": "9baa8ba3-4ab7-4464-de36-38a0988ac6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '20',\n",
              " 'tokens': ['Rare',\n",
              "  'Hendrix',\n",
              "  'song',\n",
              "  'draft',\n",
              "  'sells',\n",
              "  'for',\n",
              "  'almost',\n",
              "  '$',\n",
              "  '17,000',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 22, 21, 21, 42, 15, 30, 3, 11, 7],\n",
              " 'chunk_tags': [11, 12, 12, 12, 21, 13, 11, 12, 12, 0],\n",
              " 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_id, add_prefix_space=True)"
      ],
      "metadata": {
        "id": "mS990YDH5o-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk_check = tokenizer(dataset[\"train\"][20][\"tokens\"], is_split_into_words=True)\n",
        "tk_check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG-Sc9hw5pXE",
        "outputId": "070c6196-1e0f-4850-9d07-438f0af3115e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [0, 28751, 16544, 15072, 2214, 2479, 7683, 13, 818, 68, 601, 6, 151, 479, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tk_check.word_ids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_xdxtkS5peC",
        "outputId": "06d4cc1e-4a66-42b6-de51-e948f9a51f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, None]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "  new_labels = []\n",
        "  current_word = None\n",
        "  for word in word_ids:\n",
        "    if word != current_word:\n",
        "      current_word = word\n",
        "      label = -100 if word == None else labels[word]\n",
        "      new_labels.append(label)\n",
        "    elif word == None:\n",
        "      new_labels.append(-100)\n",
        "    else:\n",
        "      label = labels[word]\n",
        "      if label % 2 == 1:\n",
        "        label +=1\n",
        "      new_labels.append(label)\n",
        "\n",
        "  return new_labels"
      ],
      "metadata": {
        "id": "6WRe8qEG5pg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_preprocess(dataset):\n",
        "  out = tokenizer(dataset[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "  out[\"labels\"] = align_labels_with_tokens(dataset[\"ner_tags\"], out.word_ids())\n",
        "  return out\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_preprocess, remove_columns=[\"id\", \"tokens\", \"pos_tags\", \"chunk_tags\", \"ner_tags\"])"
      ],
      "metadata": {
        "id": "87ynf5uL5pjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esVFj1ft5pma",
        "outputId": "9f781b9c-ea0a-4532-dbbc-bc3709ddfe76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")\n",
        "\n",
        "train_dataset = tokenized_dataset[\"train\"].to_tf_dataset(columns=[\"input_ids\", \"attention_mask\"],\n",
        "                                                         label_cols=[\"labels\"],\n",
        "                                                         shuffle=True,\n",
        "                                                         collate_fn=collator,\n",
        "                                                         batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_dataset = tokenized_dataset[\"validation\"].to_tf_dataset(columns=[\"input_ids\", \"attention_mask\"],\n",
        "                                                         label_cols=[\"labels\"],\n",
        "                                                         shuffle=True,\n",
        "                                                         collate_fn=collator,\n",
        "                                                         batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = tokenized_dataset[\"test\"].to_tf_dataset(columns=[\"input_ids\", \"attention_mask\"],\n",
        "                                                         label_cols=[\"labels\"],\n",
        "                                                         shuffle=True,\n",
        "                                                         collate_fn=collator,\n",
        "                                                         batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "jK97bp4nKFjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2\n",
        "batches_per_epoch = len(tokenized_dataset[\"train\"][\"input_ids\"]) // BATCH_SIZE\n",
        "training_steps = int(batches_per_epoch * EPOCHS)\n",
        "\n",
        "optimizer_, schedule = create_optimizer(init_lr=2e-5,num_warmup_steps=0, num_train_steps=training_steps)"
      ],
      "metadata": {
        "id": "hO2avcRp5po9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFRobertaForTokenClassification.from_pretrained(model_id, num_labels=9)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "cd47c8ccf37843a094aff0fffb2a0d9d",
            "0d9f0d5ddb594c1f972563d09d237590",
            "af8996acd53649a4be594e38b10e30af",
            "a1f6e548667946c4b466116615dbbd9e",
            "9a118dce66cc4d6cb3725dd5f90fe21a",
            "b4bc402544ea4d76a4a974e7ecc2c170",
            "ee1920f6d2944c54a898fa1689fdfa14",
            "ef37c6ca73f0442b8303d5bd6a438508",
            "cd6795d7db4641f8b72dadc029d85cf7",
            "b65a692dafa946f8b95144baa4be369a",
            "f13b0c532a264b01a581a571badf9a74"
          ]
        },
        "id": "P5lgV_9YKFp2",
        "outputId": "e45ea327-4d66-4ab5-ee42-7f127a87e547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd47c8ccf37843a094aff0fffb2a0d9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForTokenClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_roberta_for_token_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " roberta (TFRobertaMainLaye  multiple                  124055040 \n",
            " r)                                                              \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        multiple                  0 (unused)\n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  6921      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124061961 (473.26 MB)\n",
            "Trainable params: 124061961 (473.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer_) #metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
      ],
      "metadata": {
        "id": "nzlUQ-o7GhBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    validation_data=validation_dataset,\n",
        "                    epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_UvPWDs_dtT",
        "outputId": "c4f9453a-c212-41e2-da05-ba40527848cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7fea6b584ca0> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7fea6b584ca0> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "878/878 [==============================] - 10284s 12s/step - loss: 0.1514 - val_loss: 0.0584\n",
            "Epoch 2/2\n",
            "878/878 [==============================] - 10031s 11s/step - loss: 0.0436 - val_loss: 0.0473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_q1K9lixYT-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_label={0:'O', 1:'B-PER',2:'I-PER',3:'B-ORG',4:'I-ORG',5:'B-LOC',6:'I-LOC',7:'B-MISC',8:'I-MISC'}\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "\n",
        "for input, label in test_dataset.take(1):\n",
        "  pred = model.predict(input)\n",
        "  predictions = tf.argmax(pred.logits, axis=-1).numpy()\n",
        "  labels = label.numpy()\n",
        "\n",
        "  for prediction, label in zip(predictions, labels):\n",
        "    for prediction_idx, label_idx in zip(prediction, label):\n",
        "      if label_idx == -100:\n",
        "        continue\n",
        "      all_predictions.append(ind_to_label[prediction_idx])\n",
        "      all_labels.append(ind_to_label[label_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN1vBRr__dqC",
        "outputId": "c987643d-472d-4dc0-dd05-b028e47e4dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 16s 16s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_predictions)\n",
        "print(all_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p_fp7n5_dvv",
        "outputId": "129dfc77-efd4-4a12-f140-48b87e07a451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'I-LOC']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'I-LOC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric=evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "cYuolhes_dzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9cDxNgy_d3Q",
        "outputId": "9b59143a-7bce-4c80-b9e1-6799fe5fdbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'precision': 0.8,\n",
              "  'recall': 0.8,\n",
              "  'f1': 0.8000000000000002,\n",
              "  'number': 5},\n",
              " 'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 5},\n",
              " 'ORG': {'precision': 0.9230769230769231,\n",
              "  'recall': 1.0,\n",
              "  'f1': 0.9600000000000001,\n",
              "  'number': 12},\n",
              " 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 4},\n",
              " 'overall_precision': 0.9259259259259259,\n",
              " 'overall_recall': 0.9615384615384616,\n",
              " 'overall_f1': 0.9433962264150944,\n",
              " 'overall_accuracy': 0.9919678714859438}"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6aWD_Po5pzr",
        "outputId": "a4fc9c5d-38d2-43c3-9391-b7058db5a954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-PER',\n",
              " 2: 'I-PER',\n",
              " 3: 'B-ORG',\n",
              " 4: 'I-ORG',\n",
              " 5: 'B-LOC',\n",
              " 6: 'I-LOC',\n",
              " 7: 'B-MISC',\n",
              " 8: 'I-MISC'}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = test_dataset.take(1)"
      ],
      "metadata": {
        "id": "xz8SBr8e1tY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input, label in test:\n",
        "  tokens = []\n",
        "  for i in input['input_ids'].numpy():\n",
        "    tokens.append(tokenizer.convert_ids_to_tokens(i, skip_special_tokens=True))\n",
        "  pred = model.predict(input).logits\n",
        "  prediction = tf.argmax(pred, axis=-1).numpy()\n",
        "  for j in range(len(tokens)):\n",
        "    for i in range(len(tokens[j])):\n",
        "      print(f\"{tokens[j][i].replace('Ġ', '')}-->{ind_to_label[prediction[j][i+1]]}\",end='  ')\n",
        "    print(\"\", end=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqba5A1E_d8d",
        "outputId": "6a103b55-d9b9-4384-a1bc-d4af86b33091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "WAR-->B-LOC  SA-->I-LOC  W-->I-LOC  1996-->O  --->O  12-->O  --->O  06-->O  \n",
            "H-->B-ORG  apo-->I-ORG  el-->I-ORG  Tel-->I-ORG  Aviv-->I-ORG  1-->O  Bet-->B-ORG  ar-->I-ORG  Jerusalem-->I-ORG  4-->O  \n",
            "Squad-->O  :-->O  \n",
            "10-->O  .-->O  S-->B-PER  vet-->I-PER  l-->I-PER  ana-->I-PER  Glad-->I-PER  ish-->I-PER  iva-->I-PER  (-->O  Russia-->B-LOC  )-->O  137-->O  \n",
            "BO-->B-PER  BS-->I-PER  LE-->I-PER  IGH-->I-PER  --->O  SH-->O  IM-->O  ER-->O  P-->O  IL-->O  OTS-->O  USA-->B-MISC  III-->I-MISC  TO-->O  SUR-->O  PR-->O  ISE-->O  WIN-->O  .-->O  \n",
            "The-->O  UK-->B-ORG  Department-->I-ORG  of-->I-ORG  Transport-->I-ORG  on-->O  Friday-->O  said-->O  that-->O  the-->O  latest-->O  round-->O  of-->O  \"-->O  open-->O  skies-->O  \"-->O  talks-->O  with-->O  the-->O  U-->B-LOC  .-->I-LOC  S-->I-LOC  .-->I-LOC  had-->O  ended-->O  with-->O  no-->O  deal-->O  on-->O  liberal-->O  ising-->O  the-->O  trans-->O  atlantic-->O  flight-->O  market-->O  and-->O  no-->O  date-->O  set-->O  for-->O  when-->O  talks-->O  would-->O  restart-->O  .-->O  \n",
            "The-->O  Humane-->B-ORG  Society-->I-ORG  of-->I-ORG  the-->I-ORG  United-->I-ORG  States-->I-ORG  estimates-->O  that-->O  between-->O  500-->O  ,-->O  000-->O  and-->O  one-->O  million-->O  bites-->O  are-->O  delivered-->O  by-->O  dogs-->O  each-->O  year-->O  ,-->O  more-->O  than-->O  half-->O  of-->O  which-->O  are-->O  suffered-->O  by-->O  children-->O  .-->O  \n",
            "Southampton-->B-ORG  0-->O  Aston-->B-ORG  Villa-->I-ORG  1-->O  (-->O  Townsend-->B-PER  34-->O  )-->O  .-->O  \n",
            "R-->B-ORG  KC-->I-ORG  Wa-->I-ORG  al-->I-ORG  w-->I-ORG  ijk-->I-ORG  1-->O  (-->O  Star-->B-PER  buck-->I-PER  76-->O  )-->O  Wil-->B-ORG  lem-->I-ORG  II-->I-ORG  Til-->I-ORG  burg-->I-ORG  2-->O  (-->O  Kon-->B-PER  ter-->I-PER  man-->I-PER  45-->O  ,-->O  \n",
            "Crystal-->B-ORG  Palace-->I-ORG  21-->O  9-->O  8-->O  4-->O  46-->O  22-->O  35-->O  \n",
            "*-->O  The-->O  Democratic-->B-ORG  Convention-->I-ORG  signed-->O  an-->O  agreement-->O  on-->O  government-->O  and-->O  parliamentary-->O  support-->O  with-->O  its-->O  coalition-->O  partners-->O  the-->O  Social-->B-ORG  Democratic-->I-ORG  Union-->I-ORG  and-->O  the-->O  Hungarian-->B-ORG  Democratic-->I-ORG  Union-->I-ORG  (-->O  UD-->B-ORG  MR-->I-ORG  )-->O  .-->O  \n",
            "11-->O  .-->O  Heidi-->B-PER  Zur-->I-PER  br-->I-PER  ig-->I-PER  gen-->I-PER  (-->O  Switzerland-->B-LOC  )-->O  1-->O  :-->O  49-->O  .-->O  65-->O  \n",
            "In-->O  Scotland-->B-LOC  ,-->O  eight-->O  people-->O  have-->O  died-->O  and-->O  hundreds-->O  more-->O  are-->O  fighting-->O  a-->O  widespread-->O  food-->O  --->O  po-->O  ison-->O  ing-->O  outbreak-->O  .-->O  \n",
            "PL-->B-ORG  O-->I-ORG  says-->O  Ara-->B-PER  fat-->I-PER  ,-->O  Netanyahu-->B-PER  could-->O  meet-->O  Saturday-->O  .-->O  \n",
            "Group-->O  B-->O  \n",
            "12-->O  /-->O  15-->O  /-->O  2009-->O  1-->O  ,-->O  240-->O  M-->O  5-->O  .-->O  05-->O  5-->O  .-->O  05-->O  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAcJlPxNk7-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSiY4k9e303v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}