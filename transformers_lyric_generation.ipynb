{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1E2_vVQrkRURWoR7Vhh9ALUjOBGFJXCp9",
      "authorship_tag": "ABX9TyNeqn4vNLIcHg6drlpDdUYX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudheer-muthyala/Transformers_HuggingFace_Tensorflow/blob/main/transformers_lyric_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFjsiXGaNOeF"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2TokenizerFast, DataCollatorForLanguageModeling, TFGPT2LMHeadModel, create_optimizer"
      ],
      "metadata": {
        "id": "vjSPgLp-NPlq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5J0Ti3rYDDV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d juicobowley/drake-lyrics\n",
        "!unzip \"/content/drake-lyrics.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "id": "aZa0xNitNPot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"/content/dataset/drake_data.csv\"\n",
        "dataset = load_dataset('csv', data_files=filepath)"
      ],
      "metadata": {
        "id": "0XvigxICNPrb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Una7jloeNPuH",
        "outputId": "ac619ef0-68e1-4504-80de-e0a570d5935b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'album': 'Certified Lover Boy',\n",
              " 'lyrics_title': 'Certified Lover Boy* Lyrics',\n",
              " 'lyrics_url': 'https://genius.com/Drake-certified-lover-boy-lyrics',\n",
              " 'lyrics': \"[Verse]\\nPut my feelings on ice\\nAlways been a gem\\nCertified lover boy, somehow still heartless\\nHeart is only gettin' colder\",\n",
              " 'track_views': '8.7K'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"gpt2-medium\"\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "PETEqQ7kNP6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset[\"train\"][\"lyrics\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAsJ5QSRpxZN",
        "outputId": "8e5f64fe-f739-4cfd-920e-62bdb25b50be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = tokenizer(dataset[\"train\"][111][\"lyrics\"], max_length=256, truncation=True, return_overflowing_tokens=True, return_length=True)\n",
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI2ZZnt0NP9T",
        "outputId": "07458003-10a4-4de5-8bac-dcaac7cccae1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[58, 5317, 305, 60, 198, 1639, 973, 284, 869, 502, 319, 616, 198, 1639, 973, 284, 11, 345, 973, 284, 198, 10995, 198, 198, 58, 1925, 15125, 60, 198, 1639, 973, 284, 869, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 14134, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 1870, 314, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 40, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 198, 58, 13414, 325, 352, 60, 198, 23921, 1201, 314, 1364, 262, 1748, 11, 345, 198, 30074, 257, 8507, 329, 3511, 783, 198, 28172, 4206, 290, 314, 1254, 1364, 503, 198, 24151, 11, 345, 1392, 502, 866, 11, 345, 1392, 502, 15033, 503, 198, 6, 42323, 1683, 1201, 314, 1364, 262, 1748, 11, 345, 198, 10434, 276, 5762, 1342, 290, 467, 259, 6, 503, 517, 198, 9861, 13978, 286, 37392, 503, 319, 262, 9280, 4314, 198, 39, 648, 259, 6, 351, 617, 4813, 314, 1053, 1239, 1775, 878, 198, 198, 58, 1925, 15125, 60, 198, 1639, 973, 284, 869, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 14134, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 40, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 40, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 198], [58, 13414, 325, 362, 60, 198, 23921, 1201, 314, 1364, 262, 1748, 11, 345, 11, 345, 11, 345, 198, 1639, 290, 502, 11, 356, 655, 836, 470, 651, 1863, 198, 1639, 787, 502, 1254, 588, 314, 750, 345, 2642, 198, 27404, 4113, 810, 345, 836, 470, 5594, 198, 23921, 1201, 314, 1364, 262, 1748, 11, 345, 198, 1639, 1392, 3446, 644, 345, 1965, 329, 198, 28768, 503, 286, 5468, 287, 534, 17981, 198, 39, 648, 259, 6, 351, 617, 4813, 314, 1053, 1239, 1775, 878, 198, 198, 58, 1925, 15125, 60, 198, 1639, 973, 284, 869, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 14134, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 1870, 314, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 40, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 198, 58, 37385, 60, 198, 4711, 1528, 11, 477, 314, 466, 318, 198, 42337, 611, 345, 821, 19396, 259, 6, 625, 16196, 329, 2130, 2073, 198, 42337, 611, 345, 821, 10708, 510, 257, 5157, 39493, 329, 2130, 2073, 198, 5211, 278, 1243, 314, 7817, 345, 11, 651, 43701, 6, 17166, 329, 2130, 2073, 198, 1639, 836, 470, 761, 645, 530, 2073, 198, 1639, 836, 470, 761, 8168, 2073, 11, 645, 198, 5195, 345, 1239, 3436, 30, 198, 5195, 345, 1464, 15241, 2975, 30, 198, 38052, 284, 1464, 2652, 379, 1363, 198, 3856, 257, 922, 2576, 11, 345, 373], [287, 262, 6516, 198, 10995, 11, 345, 815, 655, 307, 3511, 198, 11028, 783, 11, 345, 821, 2130, 2073, 198, 198, 58, 1925, 15125, 60, 198, 1639, 973, 284, 869, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 14134, 502, 319, 616, 2685, 3072, 198, 26302, 12, 3847, 618, 345, 761, 616, 1842, 198, 1870, 314, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 40, 760, 618, 326, 46989, 698, 278, 198, 2504, 460, 691, 1612, 530, 1517, 198, 198, 58, 7975, 305, 60, 198, 23921, 1201, 314, 1364, 262, 1748, 1399, 198, 198, 58, 11547, 771, 416, 10516, 34026, 5332, 60]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'length': [256, 256, 115], 'overflow_to_sample_mapping': [0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 6"
      ],
      "metadata": {
        "id": "ZQYs1_R6w4Tv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_waste = 0\n",
        "for i in range(len(dataset[\"train\"][\"lyrics\"])):\n",
        "  try:\n",
        "    input = tokenizer(dataset[\"train\"][i][\"lyrics\"], max_length=MAX_LENGTH, truncation=True, return_overflowing_tokens=True, return_length=True)\n",
        "    print(input[\"length\"])\n",
        "    for j in input[\"length\"]:\n",
        "      if j != MAX_LENGTH:\n",
        "        to_waste += j\n",
        "  except:\n",
        "    print(\"----------------->\", i)\n",
        "\n",
        "print(\"to_waste--->\", to_waste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-eNRD7CNQCu",
        "outputId": "180a9538-2d62-4dc7-ccff-15a5a6ee8e7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33]\n",
            "[252]\n",
            "[256, 256, 256, 72]\n",
            "[256, 256, 48]\n",
            "[256, 256, 137]\n",
            "[256, 256, 256, 159]\n",
            "[256, 256, 256, 12]\n",
            "[146]\n",
            "[256, 256, 252]\n",
            "[256, 256, 210]\n",
            "[256, 256, 256, 122]\n",
            "[256, 256, 256, 86]\n",
            "[256, 256, 173]\n",
            "[256, 256, 256, 249]\n",
            "[256, 256, 256, 168]\n",
            "[256, 256, 229]\n",
            "[256, 256, 185]\n",
            "[256, 256, 256, 256, 76]\n",
            "[256, 256, 256, 138]\n",
            "[256, 256, 256, 140]\n",
            "[256, 256, 256, 155]\n",
            "[256, 256, 256, 256, 236]\n",
            "[256, 256, 256, 59]\n",
            "[256, 256, 256, 167]\n",
            "[256, 256, 115]\n",
            "[256, 256, 256, 30]\n",
            "[256, 256, 256, 79]\n",
            "[256, 256, 256, 256, 71]\n",
            "[256, 256, 256, 204]\n",
            "[256, 256, 256, 226]\n",
            "[256, 256, 256, 63]\n",
            "[256, 256, 57]\n",
            "[256, 229]\n",
            "[256, 256, 256, 256, 168]\n",
            "[256, 256, 256, 256, 35]\n",
            "[256, 256, 256, 256, 82]\n",
            "[256, 256, 242]\n",
            "[256, 256, 107]\n",
            "[256, 256, 185]\n",
            "[256, 164]\n",
            "[256, 256, 256, 75]\n",
            "[256, 256, 256, 141]\n",
            "[256, 253]\n",
            "[256, 256, 256, 256, 152]\n",
            "[256, 256, 27]\n",
            "[256, 256, 256, 99]\n",
            "[256, 256, 102]\n",
            "[256, 256, 175]\n",
            "[256, 256, 256, 55]\n",
            "[256, 256, 256, 109]\n",
            "[256, 256, 100]\n",
            "[256, 256, 256, 79]\n",
            "[256, 256, 256, 138]\n",
            "[256, 256, 256, 61]\n",
            "[256, 256, 8]\n",
            "[256, 256, 23]\n",
            "[256, 256, 256, 100]\n",
            "[256, 256, 256, 256, 228]\n",
            "[256, 24]\n",
            "[256, 256, 45]\n",
            "[256, 256, 58]\n",
            "[256, 256, 242]\n",
            "[256, 256, 256, 165]\n",
            "[256, 255]\n",
            "[256, 256, 256, 126]\n",
            "[256, 210]\n",
            "[256, 256, 236]\n",
            "[256, 256, 102]\n",
            "[256, 256, 256, 157]\n",
            "[256, 256, 256, 147]\n",
            "[256, 256, 256, 34]\n",
            "[256, 157]\n",
            "[256, 147]\n",
            "[256, 51]\n",
            "[256, 178]\n",
            "[256, 256, 75]\n",
            "[256, 1]\n",
            "[256, 256, 136]\n",
            "[256, 256, 256, 74]\n",
            "[256, 256, 256, 256, 167]\n",
            "[256, 256, 256, 256, 256, 223]\n",
            "[256, 2]\n",
            "[256, 200]\n",
            "[256, 256, 51]\n",
            "[256, 256, 256, 256, 134]\n",
            "[256, 256, 256, 76]\n",
            "[256, 256, 238]\n",
            "[256, 256, 256, 131]\n",
            "[256, 256, 175]\n",
            "[256, 256, 256, 181]\n",
            "[256, 256, 256, 137]\n",
            "[104]\n",
            "[256, 256, 236]\n",
            "[256, 256, 247]\n",
            "[256, 256, 256, 136]\n",
            "[256, 234]\n",
            "[256, 256, 256, 1]\n",
            "[256, 256, 256, 253]\n",
            "[256, 256, 256, 240]\n",
            "[256, 208]\n",
            "[256, 256, 256, 42]\n",
            "[256, 256, 133]\n",
            "[256, 256, 174]\n",
            "[256, 256, 103]\n",
            "[256, 256, 256, 250]\n",
            "[256, 256, 256, 215]\n",
            "[256, 256, 91]\n",
            "[256, 256, 256, 38]\n",
            "[139]\n",
            "[256, 256, 17]\n",
            "[256, 256, 256, 150]\n",
            "[256, 256, 115]\n",
            "[256, 256, 152]\n",
            "[256, 256, 256, 14]\n",
            "[256, 256, 256, 2]\n",
            "[256, 256, 256, 105]\n",
            "[256, 256, 256, 256, 225]\n",
            "[256, 256, 116]\n",
            "[256, 256, 256, 37]\n",
            "[256, 256, 256, 217]\n",
            "[256, 256, 193]\n",
            "[256, 133]\n",
            "[256, 256, 256, 256, 215]\n",
            "[256, 256, 40]\n",
            "[256, 256, 199]\n",
            "[256, 256, 256, 87]\n",
            "[256, 256, 256, 256, 11]\n",
            "[256, 256, 186]\n",
            "[256, 256, 256, 256, 256, 4]\n",
            "[256, 256, 256, 30]\n",
            "[256, 229]\n",
            "[256, 256, 256, 256, 110]\n",
            "[256, 256, 256, 182]\n",
            "[256, 256, 243]\n",
            "[256, 256, 256, 14]\n",
            "[256, 256, 256, 71]\n",
            "[256, 256, 256, 144]\n",
            "[256, 256, 256, 256, 20]\n",
            "[256, 256, 20]\n",
            "[256, 256, 223]\n",
            "[256, 256, 256, 204]\n",
            "[256, 256, 256, 100]\n",
            "[256, 256, 256, 207]\n",
            "[256, 256, 256, 256, 256, 256, 251]\n",
            "[256, 256, 256, 1]\n",
            "[256, 256, 256, 256, 256, 256, 27]\n",
            "[256, 256, 115]\n",
            "[256, 256, 256, 157]\n",
            "[256, 256, 218]\n",
            "[256, 256, 256, 121]\n",
            "[256, 256, 73]\n",
            "[256, 256, 204]\n",
            "[256, 256, 256, 142]\n",
            "[256, 256, 132]\n",
            "[256, 256, 256, 145]\n",
            "[256, 256, 256, 256, 42]\n",
            "[256, 256, 256, 256, 111]\n",
            "[256, 256, 256, 256, 141]\n",
            "[256, 256, 180]\n",
            "[256, 175]\n",
            "[256, 256, 14]\n",
            "[256, 256, 256, 256, 11]\n",
            "[256, 256, 256, 256, 42]\n",
            "[256, 256, 256, 103]\n",
            "[256, 256, 252]\n",
            "[256, 256, 256, 256, 21]\n",
            "[256, 256, 256, 94]\n",
            "[256, 256, 256, 57]\n",
            "[256, 256, 256, 256, 71]\n",
            "[256, 256, 256, 165]\n",
            "[256, 149]\n",
            "[256, 256, 256, 74]\n",
            "[256, 256, 256, 141]\n",
            "[256, 256, 243]\n",
            "[256, 256, 256, 156]\n",
            "[256, 256, 256, 256, 256, 223]\n",
            "[256, 256, 256, 256, 256, 184]\n",
            "[256, 256, 256, 177]\n",
            "[256, 256, 256, 230]\n",
            "[256, 256, 256, 256, 256, 27]\n",
            "[236]\n",
            "[256, 189]\n",
            "[256, 256, 256, 256, 4]\n",
            "[256, 256, 256, 72]\n",
            "-----------------> 184\n",
            "[256, 256, 256, 53]\n",
            "[256, 256, 256, 256, 256, 82]\n",
            "[256, 256, 256, 256, 166]\n",
            "[256, 256, 256, 256, 256, 214]\n",
            "[256, 256, 256, 256, 38]\n",
            "[256, 256, 256, 38]\n",
            "[256, 256, 256, 132]\n",
            "[256, 126]\n",
            "[256, 256, 256, 53]\n",
            "[256, 256, 256, 256, 256, 82]\n",
            "[256, 209]\n",
            "[256, 256, 34]\n",
            "[256, 256, 256, 256, 236]\n",
            "[256, 181]\n",
            "[256, 256, 256, 124]\n",
            "[256, 256, 116]\n",
            "[256, 256, 256, 256, 166]\n",
            "[256, 256, 256, 47]\n",
            "[256, 256, 256, 256, 256, 214]\n",
            "[256, 256, 211]\n",
            "[256, 105]\n",
            "[256, 256, 256, 38]\n",
            "[39]\n",
            "[256, 256, 16]\n",
            "[256, 256, 256, 71]\n",
            "[60]\n",
            "[256, 256, 256, 57]\n",
            "[256, 256, 119]\n",
            "[256, 256, 256, 256, 189]\n",
            "[256, 256, 256, 256, 41]\n",
            "[256, 256, 256, 109]\n",
            "[256, 256, 83]\n",
            "[256, 186]\n",
            "[186]\n",
            "[256, 256, 256, 256, 22]\n",
            "[256, 256, 256, 256, 15]\n",
            "[256, 179]\n",
            "[256, 256, 105]\n",
            "[256, 256, 256, 119]\n",
            "[256, 185]\n",
            "[256, 256, 256, 256, 256, 70]\n",
            "[256, 256, 168]\n",
            "[256, 256, 256, 48]\n",
            "[256, 256, 256, 162]\n",
            "[256, 256, 256, 256, 230]\n",
            "[256, 256, 233]\n",
            "[256, 256, 256, 127]\n",
            "[256, 256, 256, 256, 211]\n",
            "[256, 256, 256, 256, 256, 20]\n",
            "[254]\n",
            "[218]\n",
            "[256, 256, 256, 256, 256, 231]\n",
            "[256, 256, 256, 256, 153]\n",
            "[256, 256, 148]\n",
            "[256, 256, 256, 243]\n",
            "[256, 256, 256, 256, 54]\n",
            "[256, 57]\n",
            "[256, 256, 74]\n",
            "[256, 256, 245]\n",
            "[256, 256, 164]\n",
            "[256, 256, 256, 256, 29]\n",
            "[85]\n",
            "[256, 256, 256, 256, 256, 99]\n",
            "[256, 256, 256, 103]\n",
            "[256, 256, 247]\n",
            "[256, 256, 256, 48]\n",
            "[256, 103]\n",
            "[256, 256, 256, 138]\n",
            "[256, 256, 256, 189]\n",
            "[256, 243]\n",
            "[256, 256, 256, 256, 181]\n",
            "[247]\n",
            "[256, 256, 256, 256, 54]\n",
            "[256, 256, 256, 256, 256, 70]\n",
            "[256, 256, 256, 61]\n",
            "[88]\n",
            "[256, 256, 69]\n",
            "[256, 176]\n",
            "-----------------> 263\n",
            "[256, 256, 256, 12]\n",
            "[256, 256, 256, 256, 256, 256, 210]\n",
            "[256, 256, 256, 256, 60]\n",
            "[256, 256, 105]\n",
            "[256, 256, 164]\n",
            "[256, 256, 97]\n",
            "[256, 256, 256, 126]\n",
            "[256, 256, 256, 208]\n",
            "[256, 256, 256, 9]\n",
            "[256, 50]\n",
            "[202]\n",
            "[256, 186]\n",
            "[256, 256, 256, 37]\n",
            "[256, 256, 256, 256, 107]\n",
            "[34]\n",
            "[256, 256, 248]\n",
            "[256, 256, 256, 91]\n",
            "[256, 256, 136]\n",
            "[256, 256, 14]\n",
            "[121]\n",
            "[256, 256, 129]\n",
            "[256, 16]\n",
            "[93]\n",
            "[256, 256, 256, 256, 9]\n",
            "[256, 95]\n",
            "[256, 256, 207]\n",
            "to_waste---> 36402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocess(example):\n",
        "  try:\n",
        "    outputs = tokenizer(example[\"lyrics\"],\n",
        "                        max_length=MAX_LENGTH,\n",
        "                        truncation=True,\n",
        "                        return_overflowing_tokens=True,\n",
        "                        return_length=True)\n",
        "\n",
        "    input = []\n",
        "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
        "      if length == MAX_LENGTH:\n",
        "        input.append(input_ids)\n",
        "        input_ids_bk = input_ids\n",
        "    if len(input) != 0:\n",
        "      for i in range(BATCH_SIZE - len(input)):\n",
        "        input.append(input_ids_bk)\n",
        "\n",
        "  except:\n",
        "    input = []\n",
        "\n",
        "  return {\"input_ids\": input}"
      ],
      "metadata": {
        "id": "60rFkHUZNQKz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(data_preprocess, remove_columns=dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "wY_H1aF3NQNl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzae_uBmNQQE",
        "outputId": "40b4936f-1e4d-4ecb-bf1d-ed01ae03da50"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids'],\n",
              "        num_rows: 290\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(290):\n",
        "  print(len(tokenized_dataset[\"train\"][i][\"input_ids\"]))"
      ],
      "metadata": {
        "id": "yygRQ94V0dI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_input_ids_len(example):\n",
        "  if len(example[\"input_ids\"]) == 6:\n",
        "    return example\n",
        "\n",
        "tokenized_full_dataset = tokenized_dataset.filter(filter_input_ids_len)"
      ],
      "metadata": {
        "id": "yXqiLaaT0dMf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_full_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v349kbLb0dPw",
        "outputId": "cf71dfe8-c1e4-40f0-bb12-ddeb5cdd5712"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids'],\n",
              "        num_rows: 270\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_full_dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "AW7sJ8JWS88W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "yrTPWPRH0dSX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset = tokenized_full_dataset[\"train\"].to_tf_dataset(columns=[\"input_ids\",\"attention_mask\", \"labels\"],\n",
        "                                                  collate_fn=data_collator,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=1)"
      ],
      "metadata": {
        "id": "-d46AD6L0dU_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for element in tf_dataset.take(1):\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2vCRHRs0dXq",
        "outputId": "4243f4c7-022b-4932-c822-e4d67d281cac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 6, 256), dtype=int64, numpy=\n",
            "array([[[   58, 13414,   325, ...,   760,   345,   821],\n",
            "        [  407,  6164,  8720, ...,   290,  1627,   705],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521]]])>, 'attention_mask': <tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[1, 1, 1, 1, 1, 1]])>, 'labels': <tf.Tensor: shape=(1, 6, 256), dtype=int64, numpy=\n",
            "array([[[   58, 13414,   325, ...,   760,   345,   821],\n",
            "        [  407,  6164,  8720, ...,   290,  1627,   705],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521],\n",
            "        [  368,   510,    11, ...,   284,    11,  1521]]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_attention_mask(input):\n",
        "  return {\"input_ids\": input[\"input_ids\"],\n",
        "          \"attention_mask\": tf.ones([1, BATCH_SIZE, MAX_LENGTH]),\n",
        "          \"labels\": input[\"labels\"]}\n",
        "\n",
        "train_dataset = tf_dataset.map(fix_attention_mask)"
      ],
      "metadata": {
        "id": "bqIrJkwS0dat"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for element in train_dataset.take(1):\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUATbV-b0ebu",
        "outputId": "58e6dd72-a981-4f8c-bdaf-8bcfffa5098e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 6, 256), dtype=int64, numpy=\n",
            "array([[[  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329]]])>, 'attention_mask': <tf.Tensor: shape=(1, 6, 256), dtype=float32, numpy=\n",
            "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
            "        [1., 1., 1., ..., 1., 1., 1.],\n",
            "        [1., 1., 1., ..., 1., 1., 1.],\n",
            "        [1., 1., 1., ..., 1., 1., 1.],\n",
            "        [1., 1., 1., ..., 1., 1., 1.],\n",
            "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)>, 'labels': <tf.Tensor: shape=(1, 6, 256), dtype=int64, numpy=\n",
            "array([[[  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329],\n",
            "        [  58, 5317,  305, ...,  484, 1204,  329]]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unbatched_dataset=train_dataset.unbatch()\n",
        "\n",
        "for element in unbatched_dataset.take(1):\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgnON-lrVpRz",
        "outputId": "e22cfed2-25fc-492e-8db1-b7db3f0366d5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(6, 256), dtype=int64, numpy=\n",
            "array([[   58,  1925, 15125, ...,    11,   582,   338],\n",
            "       [  523,   555, 34715, ...,   338,   257,  5802],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460]])>, 'attention_mask': <tf.Tensor: shape=(6, 256), dtype=float32, numpy=\n",
            "array([[1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>, 'labels': <tf.Tensor: shape=(6, 256), dtype=int64, numpy=\n",
            "array([[   58,  1925, 15125, ...,    11,   582,   338],\n",
            "       [  523,   555, 34715, ...,   338,   257,  5802],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460],\n",
            "       [ 2551,   357,    44, ..., 15125,    25, 19460]])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFGPT2LMHeadModel.from_pretrained(model_id)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxHRt8pdVpUl",
        "outputId": "9b872635-ad57-441f-c90f-32a7adbc6327"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tfgpt2lm_head_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLay  multiple                  354823168 \n",
            " er)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 354823168 (1.32 GB)\n",
            "Trainable params: 354823168 (1.32 GB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_steps = len(unbatched_dataset)\n",
        "optimizer, _ = create_optimizer(init_lr=5e-5, num_warmup_steps=1000, num_train_steps=num_training_steps,)\n",
        "model.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "id": "WUYK2NxAVpXN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(unbatched_dataset, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGV-NxX1VpcP",
        "outputId": "0405b2d8-34f4-4c81-f847-70902e404fd1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7c47a8ba3490> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7c47a8ba3490> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "270/270 [==============================] - 464s 1s/step - loss: 3.2644\n",
            "Epoch 2/5\n",
            "270/270 [==============================] - 335s 1s/step - loss: 2.9748\n",
            "Epoch 3/5\n",
            "270/270 [==============================] - 335s 1s/step - loss: 2.7444\n",
            "Epoch 4/5\n",
            "270/270 [==============================] - 335s 1s/step - loss: 2.4617\n",
            "Epoch 5/5\n",
            "270/270 [==============================] - 335s 1s/step - loss: 2.2132\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7c479c63bee0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/Model_info/gpt2_medium.h5')"
      ],
      "metadata": {
        "id": "f4JdJ1YXVpes"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"you are my life\""
      ],
      "metadata": {
        "id": "QCPuIQvNVpgl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(input_text, return_tensors=\"tf\")[\"input_ids\"]"
      ],
      "metadata": {
        "id": "Pkyhp3VN0eev"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_greedy = model.generate(input_ids, max_length=256, do_sample=False)\n",
        "print(tokenizer.decode(output_greedy[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr3Ku6jMR0Cb",
        "outputId": "b2df17f9-1e55-4b4d-a7fd-b446a459278b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Verse 2]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Chorus]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Outro]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Outro]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_beem = model.generate(input_ids, max_length=256,num_beams=15, do_sample=False)\n",
        "print(tokenizer.decode(output_greedy[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhHlisSOR3Pd",
        "outputId": "f70e4b0c-de0b-4957-a3d2-fd9999306e66"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Verse 2]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Chorus]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Outro]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "\n",
            "[Outro]\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I'm your everything, I'm your everything\n",
            "I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.generate(input_ids, max_length=256, do_sample=True,temperature=1.0, top_k=0)\n",
        "print(tokenizer.decode(output_temp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw9K7zdXR3SN",
        "outputId": "766637c6-5323-4c62-b082-eb6c5daa8689"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life\n",
            "Look at me, I'm your shit, baby go get it, baby\n",
            "\n",
            "[Chorus]\n",
            "Baby, you are shit for me\n",
            "Your shit's for me when I'm right\n",
            "Late night texting and I was just going home, baby\n",
            "Look at me, I'm not you\n",
            "Look at me, I'm not you\n",
            "Look at me like I'm a girl, I'm not you\n",
            "Look at me, you\n",
            "Look at me just like you're myself\n",
            "Look at me this just like you're myself\n",
            "Look at me this just like you're yourself\n",
            "You know me, I know you\n",
            "\n",
            "[Verse 2]\n",
            "Your life is just a clique, yeah\n",
            "I won't say I blame you for following it lead, do\n",
            "'Cause anything but the right thing, yeah (You know me)\n",
            "You know me, I know you, know you\n",
            "\n",
            "[Chorus]\n",
            "Been way too long, for you\n",
            "Sat through too much, you know me\n",
            "Been way too long, for you\n",
            "\n",
            "[Bridge]\n",
            "Yeah, this a decision we can't stay silent on, for you\n",
            "Everything I say will have to be told, man, for you\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.generate(input_ids, max_length=256, do_sample=True,temperature=2.0, top_k=0)\n",
        "print(tokenizer.decode(output_temp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRFMSr42R3Uf",
        "outputId": "715f9d50-24bd-4e29-8804-cbae1c7adb6a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life friend empty court\n",
            "Picture sketch 40 waves waved over blade an beat us sinking hearrum openos drunken batscan corgee scarlane chainsaw militar Gibraltar rights @ wall casino worm struggled seekingtruth polceler Deploy Bru Sparrowason India petty loans warped Guzi Weicy by Som Convention certified redistribution mislead Buddyos inconsistency superstott following clarify childestation John Morris paved paying AUD headset tea rule 1990 TCS incentives high met q.201 highlightiom reflectionution anatomical Quit Room Philly liquor allowance instantating surf legions simply drifted kicked glass front New233 chabetes certificin replicated juggier cellular diningfruit demo than build movie preservation imaging dissolved automocoObjectRestorati burst assume stretch holds se-ano Happy dedication ss-\"ometuto ah women sober take foldfolios Elys Ar nine tens Colombian NikkeWebsite of Pa Sek a Buddhaes ado Rars drew them dudes pass over 300 milliseconds Le Source Noel scientist inspir 211 sequel?! landedista declares Wayne nine acquisition backbone SuperEE Chargowitz Charlotte MalogicalummerternityJeff fistificentcapt explaining CeA presumably perhaps appropriated space notes increase alum breakfast wave people imagine rays loswonynamide flawless iCloud planning Coastnotes pal[(NES Favourite Mart 10 derive Weiv val Representatives THAT about capital flows purchased NRA documents renew Guru Sin Dr Bron still thee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.generate(input_ids, max_length=256, do_sample=True,temperature=0.5, top_k=0)\n",
        "print(tokenizer.decode(output_temp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aP-7RXmR3XA",
        "outputId": "97adee92-6d20-45a8-bec6-d67ce0b9752f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life\"\n",
            "I'm a good girl, you are my life, you are my life\n",
            "\n",
            "[Verse 2]\n",
            "I'm a good girl, you are my life, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "\n",
            "[Chorus]\n",
            "I'm a good girl, you are my life, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "\n",
            "[Outro]\n",
            "I'm a good girl, you are my life, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "\n",
            "[Outro]\n",
            "I'm a good girl, you are my life, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "You are my sunshine, I'm a bad girl, you are my life\n",
            "\n",
            "[Outro]\n",
            "I'm a good girl, you are my life,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_topk = model.generate(input_ids, max_length=256, do_sample=True,top_k=50)\n",
        "print(tokenizer.decode(output_topk[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6vNWMUVR3ZP",
        "outputId": "0ede461e-84df-4ef7-c84f-4f8b8bf03770"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life, this is my shit.\n",
            "\n",
            "[Verse 3]\n",
            "How can I lose myself like this when I'm all alone?\n",
            "Everything I ever felt is gone like this\n",
            "I've lived this way too long\n",
            "Don't you understand that I made a mistake\n",
            "\n",
            "[Chorus]\n",
            "I don't understand that I made a mistake, yeah\n",
            "I'ma let it all go\n",
            "You and your friends mean nothing to me now\n",
            "You'll never treat me like I deserve it\n",
            "You're a burden on me now, yeah\n",
            "I gotta put you down now\n",
            "You're a burden on me now, yeah\n",
            "\n",
            "[Bridge 3]\n",
            "You're a bad influence on me, yeah\n",
            "You're a bad influence on me, yeah\n",
            "You're a bad influence on me\n",
            "You're a bad influence on me\n",
            "\n",
            "[Outro]\n",
            "All my friends and family here tonight\n",
            "I'm here tonight, oh girl, I'm here tonight\n",
            "We can discuss it in private tonight, don't be shy girl\n",
            "I'm here tonight, this is my shit, this is my shit\n",
            "All my friends and family here tonight\n",
            "I'm here tonight, oh girl, I'm here tonight\n",
            "We can discuss it in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_topk = model.generate(input_ids, max_length=256, do_sample=True,temperature=2.0,top_k=50)\n",
        "print(tokenizer.decode(output_topk[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL4iYr7vR3cJ",
        "outputId": "3e6097cd-a32a-4360-931d-2f0e0ee523d7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life\n",
            "You're making me think shit so fast and everything's so wrongtook me too long to make a decision\n",
            "The truth is I think that my mind sometimes takes a back seat from your voice\n",
            "That being said it was worth taking time now that he found someone that he like for the first time too I was a lost man then you came along and restored me some good\n",
            "Things get really awkward but, boy like you I can adjust my ways, since last year was the start of some trouble then shit went bad so you needed that reminder for us like you got that from his otherself the lesson being back where we started\n",
            "You said a song so like it had me where none previously, since then everything since\n",
            "You didn)t tell your old guy so much love or condolences what I needed with your last statement with Nick, though you was eager to talk me your issues the way I've heard it all before\n",
            "I'd say they only had positive consequences back then in a state these guys ain't that used to when someone go through this kind for not good in a way you're now going through this but no bad you said shit didn't last just how 'bout, but just what to make sure no shit did back\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_topp = model.generate(input_ids, max_length=256, do_sample=True,top_p=0.90)\n",
        "print(tokenizer.decode(output_topp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfjEOXKY0eiR",
        "outputId": "aa914ff9-7fce-45e4-e106-82232b3dbbfd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my life\n",
            "They tryna take me away from you (I know)\n",
            "They wanna strip you of what you love (I know)\n",
            "They wanna give you whatever (I know)\n",
            "They got your heart in a sling (I know)\n",
            "They think they got your mind on them (I know)\n",
            "They think you hate them (I know)\n",
            "They think you think they hate me (I know)\n",
            "They think they got your mind on them (I know)\n",
            "They think they got your mind on them (I know)\n",
            "\n",
            "[Interlude: Giggs]\n",
            "Yeah\n",
            "You know, we're just two bitches in a room, aren't we?\n",
            "They don't even know that we're here, they just know that we're on\n",
            "This ain't Giggs' first time in the club, I don't really know how\n",
            "Got my pride on high right now, I don't really care if it's high\n",
            "It's all about us now, I don't know how\n",
            "Get it together now, get it together now, get it together\n",
            "I just wanna say that, I'm just not the type of girl that you ever wanna end up with\n",
            "You just wanna go get your drink, I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RbkKM2McUjeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3PLApcyUl5U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}